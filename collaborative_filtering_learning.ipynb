{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"./dataset/movies.csv\", delimiter=',', quotechar='\"')\n",
    "df_ratings = pd.read_csv(\"./dataset/ratings.csv\")\n",
    "df_movies.index = range(1,df_movies.shape[0]+1)\n",
    "\n",
    "Y, R = prepare_y_r(df_movies, df_ratings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Ynorm, Ymean = normalize_ratings(Y, R)\n",
    "\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "R = R.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(Ynorm).any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def cost_function(W, X, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y) * R\n",
    "    J = 0.5 * tf.reduce_sum(tf.square(j)) + (lambda_/2) * (tf.reduce_sum(tf.square(X)) + tf.reduce_sum(tf.square(W)))\n",
    "    return J"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "W = tf.Variable(np.random.randn(num_users, num_features), name='W')\n",
    "X = tf.Variable(np.random.randn(num_movies, num_features), name='X')\n",
    "b = tf.Variable(np.random.randn(1, num_users), name='b')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float64, numpy=1199520.2174030645>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = cost_function(W, X, b, Ynorm, R, 1)\n",
    "J"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at 0 : 10793.01\n",
      "Training loss at 20 : 10346.97\n",
      "Training loss at 40 : 9876.10\n",
      "Training loss at 60 : 9734.79\n",
      "Training loss at 80 : 9672.06\n",
      "Training loss at 100 : 9628.07\n",
      "Training loss at 120 : 9594.80\n",
      "Training loss at 140 : 9570.48\n",
      "Training loss at 160 : 9553.57\n",
      "Training loss at 180 : 9541.67\n",
      "Training loss at 200 : 9527.37\n",
      "Training loss at 220 : 9519.81\n",
      "Training loss at 240 : 9514.47\n",
      "Training loss at 260 : 9495.09\n",
      "Training loss at 280 : 9495.94\n",
      "Training loss at 300 : 9483.51\n",
      "Training loss at 320 : 9475.36\n",
      "Training loss at 340 : 9473.76\n",
      "Training loss at 360 : 9460.55\n",
      "Training loss at 380 : 9468.25\n",
      "Training loss at 400 : 9462.40\n",
      "Training loss at 420 : 9457.62\n",
      "Training loss at 440 : 9443.47\n",
      "Training loss at 460 : 9438.78\n",
      "Training loss at 480 : 9445.48\n",
      "Training loss at 500 : 9436.23\n",
      "Training loss at 520 : 9433.36\n",
      "Training loss at 540 : 9440.96\n",
      "Training loss at 560 : 9442.55\n",
      "Training loss at 580 : 9428.99\n",
      "Training loss at 600 : 9447.13\n",
      "Training loss at 620 : 9426.48\n",
      "Training loss at 640 : 9440.12\n",
      "Training loss at 660 : 9432.27\n",
      "Training loss at 680 : 9439.96\n",
      "Training loss at 700 : 9437.19\n",
      "Training loss at 720 : 9431.45\n",
      "Training loss at 740 : 9442.13\n",
      "Training loss at 760 : 9431.47\n",
      "Training loss at 780 : 9434.20\n",
      "Training loss at 800 : 9437.21\n",
      "Training loss at 820 : 9435.11\n",
      "Training loss at 840 : 9438.94\n",
      "Training loss at 860 : 9438.10\n",
      "Training loss at 880 : 9435.86\n",
      "Training loss at 900 : 9426.69\n",
      "Training loss at 920 : 9433.57\n",
      "Training loss at 940 : 9429.23\n",
      "Training loss at 960 : 9440.17\n",
      "Training loss at 980 : 9435.53\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1)\n",
    "\n",
    "num_iter = 1000\n",
    "lambda_ = 1\n",
    "for i in range(num_iter):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = cost_function(W, X, b, Ynorm, R, lambda_)\n",
    "\n",
    "    grads = tape.gradient(cost, [W, X, b])\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, [W, X, b]))\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Training loss at {i} : {cost:0.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
